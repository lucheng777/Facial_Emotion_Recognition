{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling - Image Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Chairuna, Marsya; Cheng, Lu; Heagy, David; Jiao, Hanbo; Pan, Zhongtian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we will need to install several packages required to run the modeling, e.g., pandas, numpy, sklearn, tensorflow, keras, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marsy\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.svm import SVC\n",
    "import xgboost\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Extraction and Splitting Test and Train Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part, we will conduct feature extraction and split the dataset into test and train set for training and testing the accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=os.path.dirname(os.path.dirname(os.path.realpath(\"main.ipynb\")))  \n",
    "# ...\\\\Spring2020-Project3-group2\n",
    "os.chdir(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\marsy\\\\Documents\\\\GitHub\\\\Spring2020-Project3-group2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If the above output is not correct. Please enter the filepath below to '..../Spring2020-Project3-group2/' manually. Thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/marsy/Documents/GitHub/Spring2020-Project3-group2/'\n",
    "#####################   Modify above path   #########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the path for train and test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(filepath)\n",
    "\n",
    "# testpath=filepath+'/data/test_set/'\n",
    "trainpath=filepath+'/data/train_set/'\n",
    "\n",
    "# test_image_dir = testpath + \"images/\"\n",
    "# test_pt_dir = testpath + \"points/\"\n",
    "train_image_dir = trainpath + \"images/\"\n",
    "train_pt_dir = trainpath + \"points/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the pairwise distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use sklearn to calculate the pairwise distance between the fiducial points. We will use the pairwise distance as features in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics.pairwise\n",
    "def pairwise_dist(vec):\n",
    "    dist  = sklearn.metrics.pairwise_distances(vec, metric='euclidean')\n",
    "    np.fill_diagonal(dist, np.nan)\n",
    "    return dist\n",
    "def feature(fiducial_pt_list,index):\n",
    "    pairwise_dist_feature = pairwise_dist(fiducial_pt_list[index]).flatten()\n",
    "    pairwise_dist_feature = pairwise_dist_feature[~np.isnan(pairwise_dist_feature)]\n",
    "    return pairwise_dist_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = time.time()\n",
    "dataDir = train_pt_dir\n",
    "fiducial_pt_list = []\n",
    "filelist = []\n",
    "for file in os.listdir(dataDir):\n",
    "    filelist.append(file)\n",
    "filelist.sort()\n",
    "for file in filelist:\n",
    "    fiducial_pt_list.append(scipy.io.loadmat(dataDir+file))\n",
    "    l = []\n",
    "for i in range(len(fiducial_pt_list)):\n",
    "    if 'faceCoordinatesUnwarped' in fiducial_pt_list[i].keys():\n",
    "        l.append(fiducial_pt_list[i]['faceCoordinatesUnwarped'])\n",
    "    else:\n",
    "        l.append(fiducial_pt_list[i]['faceCoordinates2'])\n",
    "        \n",
    "fiducial_pt_list = l\n",
    "\n",
    "\n",
    "X = pd.DataFrame(np.zeros((2500, 6006)))\n",
    "for i in range(2500):\n",
    "    X.iloc[i,:] = np.round(feature(fiducial_pt_list, i).flatten(), 0)\n",
    "y =pd.read_csv(trainpath+'label.csv')['emotion_idx']\n",
    "f1 = time.time()-f0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can observe that the time taken to extract the feature is ~2 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction time: 32.368s\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature Extraction time: %0.3fs\" % (f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing the machine learning technique, we wil use StandardScaler to transform our data such that its distribution will have a mean value 0 and standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "train_x_dis,test_x_dis,train_y_dis,test_y_dis=train_test_split(X,y,test_size=0.2,random_state=3662)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we use the baseline model GBM to compute the accuracy. For the advance model, we experiment with other 7 models as follows:\n",
    "* (1) KNN\n",
    "* (2) improved GBM\n",
    "* (3) XGBoost\n",
    "* (4) RandomForest\n",
    "* (5) Logistic Regression\n",
    "* (6) Support Vector Machine (SVM)\n",
    "* (7) MLP Classifier\n",
    "\n",
    "For all the candidate models, we observe the claimed accuracy, training time, and testing time. We will select the best model based on these three performance parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Claimed Accuracy</th>\n",
       "      <th>Training Time/s</th>\n",
       "      <th>Testing Time/s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bseline model:GBM</td>\n",
       "      <td>41.92%</td>\n",
       "      <td>472.039s</td>\n",
       "      <td>0.023s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>30.36%</td>\n",
       "      <td>0.481s</td>\n",
       "      <td>10.944s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Improved GBM</td>\n",
       "      <td>43.32%</td>\n",
       "      <td>1024.112s</td>\n",
       "      <td>0.034s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGboost</td>\n",
       "      <td>47.12%</td>\n",
       "      <td>129.966s</td>\n",
       "      <td>0.213s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>45.48%</td>\n",
       "      <td>7.565s</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>54.00%</td>\n",
       "      <td>37.204s</td>\n",
       "      <td>0.009s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticRegression with PCA</td>\n",
       "      <td>55.20%</td>\n",
       "      <td>12.074s</td>\n",
       "      <td>0.001s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>50.04%</td>\n",
       "      <td>20.159s</td>\n",
       "      <td>5.694s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>49.44%</td>\n",
       "      <td>328.237s</td>\n",
       "      <td>0.202s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Final model: VotingClassifier</td>\n",
       "      <td>54.32%</td>\n",
       "      <td>492.865s</td>\n",
       "      <td>6.098s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model Claimed Accuracy Training Time/s  \\\n",
       "0              Bseline model:GBM           41.92%        472.039s   \n",
       "1                            KNN           30.36%          0.481s   \n",
       "2                   Improved GBM           43.32%       1024.112s   \n",
       "3                        XGboost           47.12%        129.966s   \n",
       "4         RandomForestClassifier           45.48%          7.565s   \n",
       "5             LogisticRegression           54.00%         37.204s   \n",
       "6    LogisticRegression with PCA           55.20%         12.074s   \n",
       "7                            SVM           50.04%         20.159s   \n",
       "8                  MLPClassifier           49.44%        328.237s   \n",
       "9  Final model: VotingClassifier           54.32%        492.865s   \n",
       "\n",
       "  Testing Time/s  \n",
       "0         0.023s  \n",
       "1        10.944s  \n",
       "2         0.034s  \n",
       "3         0.213s  \n",
       "4          0.035  \n",
       "5         0.009s  \n",
       "6         0.001s  \n",
       "7         5.694s  \n",
       "8         0.202s  \n",
       "9         6.098s  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Model':['Bseline model:GBM','KNN', 'Improved GBM', 'XGboost','RandomForestClassifier','LogisticRegression', 'LogisticRegression with PCA', 'SVM','MLPClassifier','Final model: VotingClassifier'], \n",
    "        'Claimed Accuracy':['41.92%', '30.36%', '43.32%','47.12%',  '45.48%', '54.00%', '55.20%', '50.04%','49.44%','54.32%'],\n",
    "        'Training Time/s':['472.039s', '0.481s', '1024.112s','129.966s',  '7.565s', '37.204s', '12.074s','20.159s','328.237s','492.865s'],\n",
    "       'Testing Time/s':['0.023s', '10.944s', '0.034s','0.213s',  ' 0.035', '0.009s', '0.001s', '5.694s','0.202s','6.098s'],} \n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model - GBM (Claimed accuracy: 41.92%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model we used is Boosted Decision Stumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_baseline= GradientBoostingClassifier(n_estimators=100  , max_depth= 1,learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 472.039s; \n",
      "Training Accuracy : 78.1% 0.115s\n",
      "Testing Accuracy : 40.4% 0.023s\n"
     ]
    }
   ],
   "source": [
    "model=gbm_baseline\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.67      0.57        24\n",
      "           2       0.65      0.71      0.68        24\n",
      "           3       0.34      0.36      0.35        28\n",
      "           4       0.23      0.41      0.30        17\n",
      "           5       0.58      0.44      0.50        25\n",
      "           6       0.25      0.20      0.22        20\n",
      "           7       0.50      0.31      0.38        26\n",
      "           8       0.66      0.86      0.75        22\n",
      "           9       0.56      0.47      0.51        19\n",
      "          10       0.50      0.26      0.34        31\n",
      "          11       0.40      0.45      0.43        22\n",
      "          12       0.25      0.29      0.27        21\n",
      "          13       0.31      0.15      0.21        26\n",
      "          14       0.47      0.74      0.57        19\n",
      "          15       0.29      0.45      0.36        11\n",
      "          16       0.60      0.62      0.61        24\n",
      "          17       0.36      0.40      0.38        30\n",
      "          18       0.39      0.30      0.34        23\n",
      "          19       0.21      0.29      0.24        17\n",
      "          20       0.13      0.14      0.13        22\n",
      "          21       0.30      0.35      0.32        23\n",
      "          22       0.33      0.15      0.21        26\n",
      "\n",
      "    accuracy                           0.40       500\n",
      "   macro avg       0.40      0.41      0.39       500\n",
      "weighted avg       0.41      0.40      0.39       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y_dis,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then observe the performance of the candidate advance models as previously stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. KNN (Claimed accuracy: 30.36%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then proceed to run the first model using KNN. However, we decide not to proceed further with this model because the accuracy is even less than the baseline model, which is not acceptable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 4.069s; \n",
      "Training Accuracy : 42.4% 95.965s\n",
      "Testing Accuracy : 30.4% 23.103s\n"
     ]
    }
   ],
   "source": [
    "model=knn\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Improved GBM (Claimed accuracy: 43.32%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, We try to improve our baseline model by tuning one of the hyperparameter: increasing the \"max_depth\". We observed an improvement in the accuracy. However, the model fit time is significantly longer (472.039s vs. 1024.112s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_improved= GradientBoostingClassifier(n_estimators=100  , max_depth= 2,learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 1024.112s; \n",
      "Training Accuracy : 99.0% 0.174s\n",
      "Testing Accuracy : 44.2% 0.034s\n"
     ]
    }
   ],
   "source": [
    "model=gbm_improved\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then proceed with other advanced models, including XGBoost, RandomForestClassifier, LogisticRegression, SVM, MLPclassifier. We observe improvements in all accuracies and fitting times for all models.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. XGboost (Claimed accuracy: 47.12%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_model_final =xgboost.XGBClassifier(max_depth=4,n_estimators=50,learning_rate=0.1,\n",
    "                       min_child_weight=1,gamma=0,subsample=0.8,colsample_bytree=0.8,reg_alpha=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 129.966s; \n",
      "Training Accuracy : 99.8% 0.738s\n",
      "Testing Accuracy : 46.8% 0.213s\n"
     ]
    }
   ],
   "source": [
    "model=xgboost_model_final\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. RandomForestClassifier (Claimed accuracy: 45.48%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_model_final=RandomForestClassifier(n_estimators = 100, criterion = 'gini', \n",
    "                             random_state = 42, min_samples_leaf=1, max_features='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 7.565s; \n",
      "Training Accuracy : 100.0% 0.126s\n",
      "Testing Accuracy : 42.0% 0.035s\n"
     ]
    }
   ],
   "source": [
    "model=randomforest_model_final\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. LogisticRegression (Claimed accuracy: 54.00%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_final =LogisticRegression(C=0.01,\n",
    "                                         dual=False,\n",
    "                                         fit_intercept=True,\n",
    "                                         intercept_scaling=1,\n",
    "                                         max_iter=300,\n",
    "                                         multi_class='multinomial',\n",
    "                                         penalty='l2',\n",
    "                                         solver='newton-cg',\n",
    "                                         tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 37.204s; \n",
      "Training Accuracy : 82.7% 0.030s\n",
      "Testing Accuracy : 55.4% 0.009s\n"
     ]
    }
   ],
   "source": [
    "model=logistic_model_final\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. LogisticRegression with PCA (Claimed accuracy: 55.2%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_final_2 =LogisticRegression(C=0.01,\n",
    "                                         dual=False,\n",
    "                                         fit_intercept=True,\n",
    "                                         intercept_scaling=1,\n",
    "                                         max_iter=300,\n",
    "                                         multi_class='multinomial',\n",
    "                                         penalty='l2',\n",
    "                                         solver='newton-cg',\n",
    "                                         tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of components such that 99.9% variance is retained\n",
    "pca = PCA(.999)\n",
    "pca.fit(train_x_dis)\n",
    "train_x_dis_pca = pca.transform(train_x_dis)\n",
    "test_x_dis_pca = pca.transform(test_x_dis)\n",
    "pca.n_components_ # See the number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 12.074s; \n",
      "Training Accuracy : 81.8% 0.005s\n",
      "Testing Accuracy : 55.2% 0.001s\n"
     ]
    }
   ],
   "source": [
    "model = logistic_model_final_2\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis_pca,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc= model.score(train_x_dis_pca,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis_pca)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis_pca,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. SVM (Claimed accuracy: 50.04%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model_final =SVC(C=0.1,decision_function_shape='ovr',degree=2,gamma=0.1,kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 20.159s; \n",
      "Training Accuracy : 100.0% 22.935s\n",
      "Testing Accuracy : 48.6% 5.694s\n"
     ]
    }
   ],
   "source": [
    "model=svm_model_final\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Neural Network-MLPClassifier (Claimed accuracy: 49.44%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model_final =MLPClassifier(early_stopping=True,\n",
    "                              hidden_layer_sizes=(3000,),\n",
    "                              learning_rate='adaptive',\n",
    "                              solver='lbfgs',\n",
    "                              validation_fraction=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 328.237s; \n",
      "Training Accuracy : 100.0% 0.573s\n",
      "Testing Accuracy : 48.8% 0.202s\n"
     ]
    }
   ],
   "source": [
    "model=MLP_model_final\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model: VotingClassifier (Claimed accuracy: 54.32%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use VotingClassifier to combine the top models together as the final model. We can see in the following output that the testing accuracy is 53%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf_clf',randomforest_model_final),\n",
    "                ('log_clf', logistic_model_final),\n",
    "                ('svm_clf', svm_model_final),\n",
    "               ('xgb_clf', xgboost_model_final),\n",
    "                ('MLP_clf',MLP_model_final)],\n",
    "    voting='hard',\n",
    "    weights=[1,1.5,1.25,1,1.25],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fit time: 492.865s; \n",
      "Training Accuracy : 100.0% 24.127s\n",
      "Testing Accuracy : 53.6% 6.098s\n"
     ]
    }
   ],
   "source": [
    "model=voting_clf\n",
    "t0 = time.time()\n",
    "model.fit(train_x_dis,train_y_dis)\n",
    "t1 = time.time() \n",
    "training_acc=model.score(train_x_dis,train_y_dis)\n",
    "t2 = time.time() \n",
    "pred=model.predict(test_x_dis)\n",
    "t3 = time.time() \n",
    "testing_acc=model.score(test_x_dis,test_y_dis)\n",
    "\n",
    "print(\"Model fit time: %0.3fs; \" % (t1-t0))\n",
    "print(\"Training Accuracy : %0.1f%% %0.3fs\" % (training_acc*100,t2-t1))\n",
    "print(\"Testing Accuracy : %0.1f%% %0.3fs\" % (testing_acc*100,t3-t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.83      0.70        24\n",
      "           2       0.75      0.75      0.75        24\n",
      "           3       0.48      0.46      0.47        28\n",
      "           4       0.34      0.59      0.43        17\n",
      "           5       0.80      0.80      0.80        25\n",
      "           6       0.62      0.50      0.56        20\n",
      "           7       0.58      0.58      0.58        26\n",
      "           8       0.70      0.95      0.81        22\n",
      "           9       0.75      0.63      0.69        19\n",
      "          10       0.60      0.39      0.47        31\n",
      "          11       0.45      0.45      0.45        22\n",
      "          12       0.32      0.33      0.33        21\n",
      "          13       0.32      0.23      0.27        26\n",
      "          14       0.60      0.79      0.68        19\n",
      "          15       0.39      0.64      0.48        11\n",
      "          16       0.68      0.79      0.73        24\n",
      "          17       0.61      0.47      0.53        30\n",
      "          18       0.46      0.48      0.47        23\n",
      "          19       0.15      0.12      0.13        17\n",
      "          20       0.38      0.36      0.37        22\n",
      "          21       0.45      0.43      0.44        23\n",
      "          22       0.47      0.31      0.37        26\n",
      "\n",
      "    accuracy                           0.54       500\n",
      "   macro avg       0.52      0.54      0.52       500\n",
      "weighted avg       0.53      0.54      0.53       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y_dis,model.predict(test_x_dis)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
