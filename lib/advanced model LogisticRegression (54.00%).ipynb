{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report as cr\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and split them into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/jiaoh/Documents/GitHub/Spring2020-Project3-group2/'\n",
    "#####################   Modify above path   #########################\n",
    "os.chdir(filepath)\n",
    "\n",
    "# testpath=filepath+'/data/test_set/'\n",
    "trainpath=filepath+'/data/train_set/'\n",
    "\n",
    "# test_image_dir = testpath + \"images/\"\n",
    "# test_pt_dir = testpath + \"points/\"\n",
    "train_image_dir = trainpath + \"images/\"\n",
    "train_pt_dir = trainpath + \"points/\"\n",
    "\n",
    "import sklearn.metrics.pairwise\n",
    "def pairwise_dist(vec):\n",
    "    dist  = sklearn.metrics.pairwise_distances(vec, metric='euclidean')\n",
    "    np.fill_diagonal(dist, np.nan)\n",
    "    return dist\n",
    "def feature(fiducial_pt_list,index):\n",
    "    pairwise_dist_feature = pairwise_dist(fiducial_pt_list[index]).flatten()\n",
    "    pairwise_dist_feature = pairwise_dist_feature[~np.isnan(pairwise_dist_feature)]\n",
    "    return pairwise_dist_feature\n",
    "\n",
    "f0 = time.time()\n",
    "dataDir = train_pt_dir\n",
    "fiducial_pt_list = []\n",
    "filelist = []\n",
    "for file in os.listdir(dataDir):\n",
    "    filelist.append(file)\n",
    "filelist.sort()\n",
    "for file in filelist:\n",
    "    fiducial_pt_list.append(scipy.io.loadmat(dataDir+file))\n",
    "    l = []\n",
    "for i in range(len(fiducial_pt_list)):\n",
    "    if 'faceCoordinatesUnwarped' in fiducial_pt_list[i].keys():\n",
    "        l.append(fiducial_pt_list[i]['faceCoordinatesUnwarped'])\n",
    "    else:\n",
    "        l.append(fiducial_pt_list[i]['faceCoordinates2'])\n",
    "        \n",
    "fiducial_pt_list = l\n",
    "\n",
    "\n",
    "X = pd.DataFrame(np.zeros((2500, 6006)))\n",
    "for i in range(2500):\n",
    "    X.iloc[i,:] = np.round(feature(fiducial_pt_list, i).flatten(), 0)\n",
    "y =pd.read_csv(trainpath+'label.csv')['emotion_idx']\n",
    "f1 = time.time()-f0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "train_x_dis,test_x_dis,train_y_dis,test_y_dis=train_test_split(X,y,test_size=0.2,random_state=3662)\n",
    "X_dis=X\n",
    "y_dis=y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GridsearchCV to determine Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=8)]: Done  48 out of  48 | elapsed: 29.2min finished\n",
      "E:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=8,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 50], 'dual': [False],\n",
       "                         'fit_intercept': [True], 'intercept_scaling': [1],\n",
       "                         'max_iter': [300], 'multi_class': ['multinomial'],\n",
       "                         'penalty': ['l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
       "                         'tol': [0.0001]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# logistic_parm_gs = {\n",
    "#     'C': [0.01,0.1,1,50] ,\n",
    "#     'solver': ['newton-cg','lbfgs', 'sag','saga'],\n",
    "#     'multi_class' : [ 'multinomial'],\n",
    "#     'max_iter':[300],\n",
    "#     'intercept_scaling':[1],\n",
    "#     'dual':[False],\n",
    "#     'fit_intercept':[True], \n",
    "#     'penalty':['l2'],\n",
    "#     'tol':[0.0001],\n",
    "# }\n",
    "# logistic_model_gs = LogisticRegression()\n",
    "# logistic_gsearch = GridSearchCV(estimator = logistic_model_gs, \n",
    "#                         param_grid = logistic_parm_gs, \n",
    "#                         scoring ='accuracy',\n",
    "#                         cv = 3,\n",
    "#                         n_jobs = 8,\n",
    "#                         verbose=3,\n",
    "#                         return_train_score=True\n",
    "#                        )\n",
    "# logistic_gsearch.fit(train_x_dis,train_y_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset Accuracy\n",
      "0.9315\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score \n",
    "# print(\"Training dataset Accuracy\")\n",
    "# train_preds = logistic_gsearch.predict(train_x_dis)\n",
    "# train_accuracy = accuracy_score(train_y_dis, train_preds) \n",
    "# print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset Accuracy\n",
      "0.518\n"
     ]
    }
   ],
   "source": [
    "# print(\"Testing dataset Accuracy\")\n",
    "# test_preds = logistic_gsearch.predict(test_x_dis)\n",
    "# test_accuracy = accuracy_score(test_y_dis, test_preds) \n",
    "# print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'max_iter': 300,\n",
       " 'multi_class': 'multinomial',\n",
       " 'penalty': 'l2',\n",
       " 'solver': 'newton-cg',\n",
       " 'tol': 0.0001}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_gsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use K-Fold to estimate the accuracy (54.00%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_final =LogisticRegression(C=0.01,\n",
    "                                         dual=False,\n",
    "                                         fit_intercept=True,\n",
    "                                         intercept_scaling=1,\n",
    "                                         max_iter=300,\n",
    "                                         multi_class='multinomial',\n",
    "                                         penalty='l2',\n",
    "                                         solver='newton-cg',\n",
    "                                         tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.00% (3.48%)\n"
     ]
    }
   ],
   "source": [
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(logistic_model_final, X_dis,y_dis, cv=kfold)\n",
    "# print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the final model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 72.013s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "logistic_model_final.fit(X_dis,y_dis)\n",
    "print(\"done in %0.3fs\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_model_final.m']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(logistic_model_final,'logistic_model_final.m')#please change the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.load('C:/Users/jiaoh/Documents/GitHub/Spring2020-Project3-group2/hanbojiao_test/doc/logistic_model_final.m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
