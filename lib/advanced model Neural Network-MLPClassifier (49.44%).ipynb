{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import xgboost\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and split them into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'C:/Users/jiaoh/Documents/GitHub/Spring2020-Project3-group2/'\n",
    "#####################   Modify above path   #########################\n",
    "os.chdir(filepath)\n",
    "\n",
    "# testpath=filepath+'/data/test_set/'\n",
    "trainpath=filepath+'/data/train_set/'\n",
    "\n",
    "# test_image_dir = testpath + \"images/\"\n",
    "# test_pt_dir = testpath + \"points/\"\n",
    "train_image_dir = trainpath + \"images/\"\n",
    "train_pt_dir = trainpath + \"points/\"\n",
    "\n",
    "import sklearn.metrics.pairwise\n",
    "def pairwise_dist(vec):\n",
    "    dist  = sklearn.metrics.pairwise_distances(vec, metric='euclidean')\n",
    "    np.fill_diagonal(dist, np.nan)\n",
    "    return dist\n",
    "def feature(fiducial_pt_list,index):\n",
    "    pairwise_dist_feature = pairwise_dist(fiducial_pt_list[index]).flatten()\n",
    "    pairwise_dist_feature = pairwise_dist_feature[~np.isnan(pairwise_dist_feature)]\n",
    "    return pairwise_dist_feature\n",
    "\n",
    "f0 = time.time()\n",
    "dataDir = train_pt_dir\n",
    "fiducial_pt_list = []\n",
    "filelist = []\n",
    "for file in os.listdir(dataDir):\n",
    "    filelist.append(file)\n",
    "filelist.sort()\n",
    "for file in filelist:\n",
    "    fiducial_pt_list.append(scipy.io.loadmat(dataDir+file))\n",
    "    l = []\n",
    "for i in range(len(fiducial_pt_list)):\n",
    "    if 'faceCoordinatesUnwarped' in fiducial_pt_list[i].keys():\n",
    "        l.append(fiducial_pt_list[i]['faceCoordinatesUnwarped'])\n",
    "    else:\n",
    "        l.append(fiducial_pt_list[i]['faceCoordinates2'])\n",
    "        \n",
    "fiducial_pt_list = l\n",
    "\n",
    "\n",
    "X = pd.DataFrame(np.zeros((2500, 6006)))\n",
    "for i in range(2500):\n",
    "    X.iloc[i,:] = np.round(feature(fiducial_pt_list, i).flatten(), 0)\n",
    "y =pd.read_csv(trainpath+'label.csv')['emotion_idx']\n",
    "f1 = time.time()-f0\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "train_x_dis,test_x_dis,train_y_dis,test_y_dis=train_test_split(X,y,test_size=0.2,random_state=3662)\n",
    "X_dis=X\n",
    "y_dis=y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GridsearchCV to determine Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 42 candidates, totalling 126 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed: 41.3min\n",
      "[Parallel(n_jobs=2)]: Done 126 out of 126 | elapsed: 231.8min finished\n",
      "E:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_iter=200,\n",
       "                                     momentum=0.9, n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_sta...\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=2,\n",
       "             param_grid={'early_stopping': [True],\n",
       "                         'hidden_layer_sizes': [(1000,), (1000, 1000), (2000,),\n",
       "                                                (2000, 1000), (3000,),\n",
       "                                                (1000, 2000),\n",
       "                                                (1000, 1000, 1000)],\n",
       "                         'learning_rate': ['adaptive', 'constant'],\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam'],\n",
       "                         'validation_fraction': [0.2]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# MLP_parm_gs = {\n",
    "#     'hidden_layer_sizes': [(1000,), (1000,1000), (2000,), (2000,1000), (3000,), (1000,2000), (1000,1000,1000)],\n",
    "#     'learning_rate':['adaptive', 'constant'],\n",
    "#     'solver':['lbfgs','sgd','adam'],\n",
    "#     'early_stopping':[True] , \n",
    "#     'validation_fraction':[0.2],\n",
    "                        \n",
    "# }\n",
    "# MLP_model_gs = MLPClassifier()\n",
    "# MLP_gsearch = GridSearchCV(estimator = MLP_model_gs, \n",
    "#                         param_grid = MLP_parm_gs, \n",
    "#                         scoring ='accuracy',\n",
    "#                         cv = 3,\n",
    "#                         n_jobs = 2,\n",
    "#                         verbose=3,\n",
    "#                         return_train_score=True\n",
    "#                        )\n",
    "# MLP_gsearch.fit(train_x_dis,train_y_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset Accuracy\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score \n",
    "# print(\"Training dataset Accuracy\")\n",
    "# train_preds = MLP_gsearch.predict(train_x_dis)\n",
    "# train_accuracy = accuracy_score(train_y_dis, train_preds) \n",
    "# print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataset Accuracy\n",
      "0.49\n"
     ]
    }
   ],
   "source": [
    "# print(\"Testing dataset Accuracy\")\n",
    "# test_preds = MLP_gsearch.predict(test_x_dis)\n",
    "# test_accuracy = accuracy_score(test_y_dis, test_preds) \n",
    "# print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'early_stopping': True,\n",
       " 'hidden_layer_sizes': (3000,),\n",
       " 'learning_rate': 'adaptive',\n",
       " 'solver': 'lbfgs',\n",
       " 'validation_fraction': 0.2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP_gsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use K-Fold to estimate the accuracy (49.44%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_model_final =MLPClassifier(early_stopping=True,\n",
    "                              hidden_layer_sizes=(3000,),\n",
    "                              learning_rate='adaptive',\n",
    "                              solver='lbfgs',\n",
    "                              validation_fraction=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 49.44% (4.31%)\n"
     ]
    }
   ],
   "source": [
    "# kfold = KFold(n_splits=10, shuffle=True)\n",
    "# results = cross_val_score(MLP_model_final, X_dis,y_dis, cv=kfold)\n",
    "# print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the final model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 171.824s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "MLP_model_final.fit(X_dis,y_dis)\n",
    "print(\"done in %0.3fs\" % (time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLP_model_final.m']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(MLP_model_final,'MLP_model_final.m')#please change the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.load('C:/Users/jiaoh/Documents/GitHub/Spring2020-Project3-group2/hanbojiao_test/doc/MLP_model_final.m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
